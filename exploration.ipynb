{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497819, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer \n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from parapply import parapply\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import fasttext\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv(sys.path[0]+'/train.csv',sep=',',dtype=object)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data,n_jobs = 1):\n",
    "\n",
    "    for character in string.punctuation:\n",
    "        data['name_1'] = data['name_1'].apply(lambda x: str(x).replace(character, ''))\n",
    "        data['name_2'] = data['name_2'].apply(lambda x: str(x).replace(character, ''))\n",
    "\n",
    "    data['lang_1'] = parapply(data['name_1'],lambda x: detect(x),n_jobs=n_jobs)\n",
    "    data['lang_2'] = parapply(data['name_2'],lambda x: detect(x),n_jobs=n_jobs)\n",
    "\n",
    "    lang_ru_indexes =data[data['lang_1']=='ru'].index\n",
    "    print(lang_ru_indexes)\n",
    "    if len(list(lang_ru_indexes))==0:\n",
    "        lang_other_indexes = data.index\n",
    "    else:\n",
    "        lang_other_indexes =data.index.drop(lang_ru_indexes)\n",
    "    stemmer_ru = SnowballStemmer(\"russian\")\n",
    "    stemmer_other = SnowballStemmer(\"english\")\n",
    "\n",
    "    if len(list(lang_ru_indexes))!=0:\n",
    "        data.loc[lang_ru_indexes,'name_1_stemmed'] = parapply(data.loc[lang_ru_indexes,'name_1'],lambda x: stemmer_ru.stem(x),n_jobs=4)\n",
    "        data.loc[lang_other_indexes,'name_1_stemmed'] = parapply(data.loc[lang_other_indexes,'name_1'],lambda x: stemmer_other.stem(x),n_jobs=4)\n",
    "    else:\n",
    "        data.loc[lang_other_indexes,'name_1_stemmed'] = parapply(data.loc[lang_other_indexes,'name_1'],lambda x: stemmer_other.stem(x),n_jobs=4)\n",
    "\n",
    "    lang_ru_indexes =data[data['lang_2']=='ru'].index\n",
    "    print(lang_ru_indexes)\n",
    "    if len(list(lang_ru_indexes))==0:\n",
    "        lang_other_indexes = data.index\n",
    "    else:\n",
    "        lang_other_indexes =data.index.drop(lang_ru_indexes)\n",
    "    stemmer_ru = SnowballStemmer(\"russian\")\n",
    "    stemmer_other = SnowballStemmer(\"english\")\n",
    "\n",
    "    if len(list(lang_ru_indexes))!=0:\n",
    "        data.loc[lang_ru_indexes,'name_2_stemmed'] = parapply(data.loc[lang_ru_indexes,'name_2'],lambda x: stemmer_ru.stem(x),n_jobs=n_jobs)\n",
    "        data.loc[lang_other_indexes,'name_2_stemmed'] = parapply(data.loc[lang_other_indexes,'name_2'],lambda x: stemmer_other.stem(x),n_jobs=n_jobs)\n",
    "    else:\n",
    "        data.loc[lang_other_indexes,'name_2_stemmed'] = parapply(data.loc[lang_other_indexes,'name_2'],lambda x: stemmer_other.stem(x),n_jobs=n_jobs)\n",
    "   \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def cos_sim(a, b):\n",
    "\tdot_product = np.dot(a, b)\n",
    "\tnorm_a = np.linalg.norm(a)\n",
    "\tnorm_b = np.linalg.norm(b)\n",
    "\treturn dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  3371,   4944,   5885,  19271,  19550,  23412,  23865,  24518,\n",
      "             26757,  28619,\n",
      "            ...\n",
      "            482326, 483872, 488071, 488150, 489129, 489726, 493907, 493995,\n",
      "            494227, 497367],\n",
      "           dtype='int64', length=176)\n",
      "Int64Index([   384,    469,   3808,   4354,   5153,   5450,   5470,   5817,\n",
      "              6114,   7185,\n",
      "            ...\n",
      "            489237, 489511, 489553, 491734, 492110, 494314, 495064, 495335,\n",
      "            497139, 497231],\n",
      "           dtype='int64', length=833)\n"
     ]
    }
   ],
   "source": [
    "# dataset = preprocessing(data,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.to_csv(sys.path[0]+'/CompanyNamesSimularity_dataset.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(sys.path[0]+'/CompanyNamesSimularity/CompanyNamesSimularity_dataset.csv',sep=';',dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 4M words\n",
      "Number of words:  16376\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   91671 lr:  0.000000 avg.loss:  0.560611 ETA:   0h 0m 0s 11.4% words/sec/thread:   92038 lr:  0.088605 avg.loss:  1.401040 ETA:   0h 0m22s 79.4% words/sec/thread:   91801 lr:  0.020582 avg.loss:  0.620099 ETA:   0h 0m 5s\n",
      "Read 4M words\n",
      "Number of words:  16376\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:  148018 lr:  0.000000 avg.loss:  0.524437 ETA:   0h 0m 0s 22.9% words/sec/thread:  150333 lr:  0.038560 avg.loss:  1.017529 ETA:   0h 0m16s 29.7% words/sec/thread:  152404 lr:  0.035157 avg.loss:  0.888536 ETA:   0h 0m15s 39.3% words/sec/thread:  151888 lr:  0.030355 avg.loss:  0.785320 ETA:   0h 0m13s 64.6% words/sec/thread:  150659 lr:  0.017675 avg.loss:  0.631490 ETA:   0h 0m 7s 81.4% words/sec/thread:  149454 lr:  0.009293 avg.loss:  0.569469 ETA:   0h 0m 4s\n",
      "Read 4M words\n",
      "Number of words:  16376\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:  189289 lr:  0.000000 avg.loss:  0.887074 ETA:   0h 0m 0s  3.6% words/sec/thread:  212494 lr:  0.009638 avg.loss:  2.959723 ETA:   0h 0m21s 25.5% words/sec/thread:  178872 lr:  0.007446 avg.loss:  1.751832 ETA:   0h 0m19s 48.7% words/sec/thread:  184515 lr:  0.005125 avg.loss:  1.286153 ETA:   0h 0m13s 50.8% words/sec/thread:  184741 lr:  0.004923 avg.loss:  1.258441 ETA:   0h 0m12s 52.9% words/sec/thread:  185159 lr:  0.004714 avg.loss:  1.231673 ETA:   0h 0m11s 55.0% words/sec/thread:  185583 lr:  0.004504 avg.loss:  1.210243 ETA:   0h 0m11s 65.8% words/sec/thread:  187167 lr:  0.003421 avg.loss:  1.096196 ETA:   0h 0m 8s 80.4% words/sec/thread:  188683 lr:  0.001961 avg.loss:  0.983507 ETA:   0h 0m 4s\n"
     ]
    }
   ],
   "source": [
    "model_1 = fasttext.train_unsupervised(input=sys.path[0]+'/train_strings.csv',model=\"skipgram\", minn=2, maxn=5, dim=300,epoch=5, lr=0.1,thread=10)\n",
    "model_2 = fasttext.train_unsupervised(input=sys.path[0]+'/train_strings.csv',model=\"skipgram\", minn=2, maxn=5, dim=150,epoch=7, lr=0.05,thread=10)\n",
    "model_3 = fasttext.train_unsupervised(input=sys.path[0]+'/train_strings.csv',model=\"skipgram\", minn=2, maxn=5, dim=100,epoch=10, lr=0.01,thread=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save_model(sys.path[0]+'/model_1.bin')\n",
    "model_2.save_model(sys.path[0]+'/model_2.bin')\n",
    "model_3.save_model(sys.path[0]+'/model_3.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = fasttext.load_model(sys.path[0]+'/model_1.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['is_duplicate'] = dataset['is_duplicate'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3658, 8) (497819,)\n"
     ]
    }
   ],
   "source": [
    "dataset_val = dataset[dataset['is_duplicate']==1]\n",
    "dataset_val = dataset_val.reset_index(drop=True)\n",
    "Y = dataset['name_2_stemmed']\n",
    "print(dataset_val.shape, Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_Y = np.zeros((dataset.shape[0],300),dtype='float32')\n",
    "for i,sentence in enumerate(Y):\n",
    "    embeddings_Y[i,:] = model_1.get_sentence_vector(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4955/4136843365.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdistances_argmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimularity_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_tuple_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_1_stemmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msimularity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1144\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4955/4136843365.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdistances_argmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimularity_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_tuple_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_1_stemmed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msimularity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4955/4136843365.py\u001b[0m in \u001b[0;36msimularity\u001b[0;34m(y, Y, embeddings, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mvector_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdistances_argmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4955/3993243617.py\u001b[0m in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mnorm_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mnorm_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot_product\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnorm_a\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnorm_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2525\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_val['names_1_simularity'] = None\n",
    "dataset_val['min_1_distance'] = 0\n",
    "results_tuple_list = []\n",
    "\n",
    "def simularity(y,Y=Y,embeddings = embeddings_Y,model=model_1):\n",
    "    distances_argmin = []\n",
    "    simularity_values = []\n",
    "    distances = np.zeros(embeddings.shape[0])\n",
    "    vector_i = model.get_sentence_vector(y) \n",
    "\n",
    "    for j, sentence_j in enumerate(Y):\n",
    "        vector_j = embeddings[j,:]\n",
    "        distances[j] = cos_sim(vector_i,vector_j)\n",
    "\n",
    "    distances_argmin = Y[np.argmax(distances)]\n",
    "    simularity_values = np.max(distances)\n",
    "\n",
    "    return (distances_argmin, simularity_values)\n",
    "\n",
    "results_tuple_list.append(dataset_val['name_1_stemmed'].apply(lambda x: simularity(x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val['names_1_simularity'] = [i[0] for i in results_tuple_list]\n",
    "dataset_val['target'] = dataset_val['name_2_stemmed']==dataset_val['names_1_simularity']\n",
    "dataset_val['target'] = dataset_val['target'].astype(int)\n",
    "dataset_val['is_duplicate'] = dataset_val['is_duplicate'].astype(int)\n",
    "\n",
    "\n",
    "print('accuracy_score= ',round(accuracy_score(data_1['is_duplicate'],data_1['target']),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
